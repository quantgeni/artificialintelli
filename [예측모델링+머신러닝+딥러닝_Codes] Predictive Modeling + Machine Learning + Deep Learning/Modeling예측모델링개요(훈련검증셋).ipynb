{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml03training.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"erkhlkT3jLyd","colab_type":"code","outputId":"a2b33950-4d99-46fc-d5aa-b0cf71cee960","executionInfo":{"status":"ok","timestamp":1561602100227,"user_tz":-540,"elapsed":740,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["# 과적합 vs. 과소적합\n","\n","# 훈련 데이터가 가지고 있는 특성을 너무 많이 반영하게 되면\n","# 훈련 데이터의 패턴을 너무 잘 인식하게 되는 문제 발생\n","\n","# 이럴 경우 새로운 데이터가 주어지면 정확하게 예측하는 일반화 능력은 떨어짐\n","\n","# 편향과 분산\n","# 편향 : 예측값과 정답이 얼마나 떨어졌는가?\n","# 분산 : 데이터들이 서로 얼마나 가깝게 붙어 있는가?\n","# 따라서, 편향이 높으면 과적합의 문제 발생\n","\n","# 훈련 데이터와 테스트 데이터\n","# => 머신러닝 모델을 만들기 위해서는\n","# 훈련/테스트 데이터로 나눠 교차검증 방식으로 모델을 만들고 성능을 평가함\n","\n","# 훈련 데이터 : 모델 추정 및 학습이 목적\n","# 테스트 데이터 : 모델 성능 평가가 목적\n","\n","# 분할 비율은 7:3 또는 8:2로 설정함\n","\n","import sklearn\n","import image\n","import seaborn as sns\n","from sklearn.datasets import load_iris\n","from sklearn.datasets import load_boston\n","from sklearn.datasets import load_digits\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.datasets import make_blobs\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","import pandas as pd\n","from pandas.plotting import scatter_matrix\n","import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler \n","\n","iris = load_iris()\n","dt_clf = DecisionTreeClassifier() # 의사결정나무\n","print(df_clf) \n","\n","train_data = iris.data # iris 데이터\n","train_label = iris.target # iris 품종\n","\n","dt_clf.fit(train_data, train_label) # 주어진 종속/돕립변수를 이용해서 학습시킴\n","\n","predict = dt_clf.predict(train_data) # 학습된 모델에 데이터를 이용해서 예측시킴\n","print('모델 정확도', accuracy_score(train_label, predict))\n","\n","\n","# => fit(학습) 시킨 데이터와 accuracy 산정을 위해 predict시킨 데이터가 동일 셋.\n","# => 따라서 정확도 1.0 (100%) 출력 =====> 뭔가 이상?!?!!\n","\n","# 모델을 학습시킬 때 사용한 데이터를 모델을 평가할때도 사용함\n","\n","# 비유) 문제집으로 시험공부 했는데 시험문제가 해당 문제집에서 다 나온 경우 100점 받음\n","\n","# 이런 문제를 피하려면 데이터셋을 \n","# 훈련 vs. 테스트 로 나눠 학습/예측 수행해야 함\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n","                       max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort=False,\n","                       random_state=None, splitter='best')\n","모델 정확도 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t6wLKXtQvQi-","colab_type":"code","outputId":"6d376129-ef28-4473-ef84-ee0336187c13","executionInfo":{"status":"ok","timestamp":1561603930875,"user_tz":-540,"elapsed":705,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":308}},"source":["# 데이터를 학습용/평가용 데이터로 분할 1 ------------------------------------------------------------------------------------------\n","# 학습용/평가용 데이터 비율은 7:3으로 설정\n","# iris데이터셋의 총 갯수는 150개\n","# 따라서, 105 : 45로 나눔\n","\n","# print(iris.data)\n","iris_train = iris.data[0:105,]\n","iris_test = iris.data[105:,]\n","#print(iris_train.shape, iris_test.shape)\n","\n","#print(iris.target)\n","\n","itarget_train = iris.target[0:105,]\n","itarget_test = iris.target[105:,]\n","#print(itarget_train.shape, itarget_test.shape)\n","\n","\n","dt_clf = DecisionTreeClassifier() # 의사결정나무\n","\n","\n","dt_clf.fit(iris_train, itarget_train) # 주어진 종속/돕립변수를 이용해서 학습시킴\n","\n","predict = dt_clf.predict(iris_test) # 학습된 모델에 데이터를 이용해서 예측시킴\n","print('모델 정확도', accuracy_score(itarget_test, predict))\n","\n","print('-----------------------------------------------')\n","print(itarget_train)\n","print('-----------------------------------------------')\n","print(itarget_test)\n","print('-----------------------------------------------')\n","print(pd.DataFrame(itarget_train)[0].value_counts())\n","print('-----------------------------------------------')\n","print(pd.DataFrame(itarget_test)[0].value_counts())\n","\n","\n","# 데이터를 순서대로 분할했기 때문에 데이터의 비율이 일정하지 않음\n","# 즉, setosa, versicolor, virginica의 비율이 같아야 하는데 train에는 setosa, versicolor가\n","# test에는 virginica 위주로 구성됨 -_-;;\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["모델 정확도 0.7333333333333333\n","-----------------------------------------------\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n","-----------------------------------------------\n","[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2]\n","-----------------------------------------------\n","1    50\n","0    50\n","2     5\n","Name: 0, dtype: int64\n","-----------------------------------------------\n","2    45\n","Name: 0, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KPQTl5bS2PfV","colab_type":"code","outputId":"dd8202d8-9126-4ffa-ef1d-bd371e82848b","executionInfo":{"status":"error","timestamp":1561606201864,"user_tz":-540,"elapsed":858,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["\n","# 데이터를 학습용/평가용 데이터로 분할 2 ------------------------------------------------------------------------------------------\n","np.random.seed(1906271215)\n","idx = np.arange(0,150)\n","train_idx = np.random.choice(idx, 105, replace=False)\n","\n","print(train_idx)\n","print(idx.shape)\n","print(train_idx.shape)\n","\n","# ... 134, 144, 26, 124, 33])\n","\n","#print(train_idx)\n","#print(-train_idx)\n","\n","X_train = iris.data[train_idx]\n","\n","print(len(train_idx))\n","mask = np.ones(len(train_idx), np.bool)\n","\n","print(mask)\n","\n","mask[train_idx] = False\n","# inverse indexing을 구현하기 위해 masking할 배열을 생성\n","\n","print(mask)\n","\n","\n","X_test = iris.data[mask] # boolean index\n","print(X_train.shape, X_test.shape)\n","\n","\n","\n","\n","Y_train = iris.target[train_idx]\n","#Y_test = iris.target[]\n","print(Y_train.shape, Y_test.shape)\n","\n","print(pd.DataFrame(Y_train)[0].value_counts())\n"," \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 14  40 106 122  34 133 147 136  38 139  69  27 114 116  84  33  21  36\n"," 145 138  60  25  70  78 124  90  55 130  76  45  91  77 143   9 111  50\n","  92 110 103 107  63 125 100  79  73   8  10 131 126  43  61  83 149  41\n","  42  35 142 127 137  30 141  47  22 112  44 104 140  53  94  80  56  68\n","  64  20   1  15  11 128  98  39 105  28  59 132  82  16  26  87 146   7\n","  86 123  32 101  13  19  58  24 113   3  96 121   4 119  99]\n","(150,)\n","(105,)\n","105\n","[ True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True]\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-7611314d9f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# inverse indexing을 구현하기 위해 masking할 배열을 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 106 is out of bounds for axis 0 with size 105"]}]},{"cell_type":"code","metadata":{"id":"LcDNvdBJ5ktu","colab_type":"code","outputId":"3d90cffa-9197-494f-a3fb-8f67836956bd","executionInfo":{"status":"ok","timestamp":1561606588383,"user_tz":-540,"elapsed":672,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":672}},"source":["## 데이터를 학습용/평가용 데이터로 분할 2\n","\n","np.random.seed(1906271215)\n","\n","idx = np.arange(0, 150)\n","\n","train_idx = np.random.choice(idx, 105, replace=False)\n","# ... 134, 144,  26, 124, 33])\n","\n","X_train = iris.data[train_idx]\n","\n","mask = np.ones(len(iris.data), np.bool) # 150개의 True를 가진 배열리스트(?) 생성됨\n","\n","print(mask)\n","\n","mask[train_idx] = False # 위 150개 True를 가진 mask에 대해, train_idx를 위치값으로 적용, mask 배열에서 해당값들만 False로 바꿔줌 \n","# 즉, 105개가 False로 변하고, 45개의 True 가짐\n","\n","\n","\n","# inverse indexing을 구현하기 위해 masking할 배열을 생성\n","print(mask)\n","\n","\n","X_test = iris.data[mask]   # 불린 인덱스\n","print(X_train.shape, X_test.shape)\n","\n","\n","Y_train = iris.target[train_idx] \n","Y_test = iris.target[mask]\n","print(Y_train.shape, Y_test.shape)\n","\n","print(Y_train)\n","print(pd.DataFrame(Y_train)[0].value_counts())\n","# 2    38\n","# 0    36\n","\n","dt_clf = DecisionTreeClassifier()\n","dt_clf.fit(X_train, Y_train)\n","\n","predict = dt_clf.predict(X_test)\n","print('모델정확도', accuracy_score(Y_test, predict))\n","\n","\n","# 모델 정확도 0.96\n","# 학습은 일정 비율의 setosa, versicolor, virginica. 그러나 여전히 고르지 않음?"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True]\n","[ True False  True False False  True  True False False False False False\n","  True False False False False  True  True False False False False  True\n"," False False False False False  True False  True False False False False\n"," False  True False False False False False False False False  True False\n","  True  True False  True  True False  True False False  True False False\n"," False False  True False False  True  True  True False False False  True\n","  True False  True  True False False False False False  True False False\n"," False  True False False  True  True False False False  True False  True\n"," False  True False False False False  True False False False False False\n","  True  True False False False False False  True False  True  True False\n","  True False False False False False False False False  True False False\n"," False False  True  True False False False False False False False False\n","  True False False False  True False]\n","(105, 4) (45, 4)\n","(105,) (45,)\n","[0 0 2 2 0 2 2 2 0 2 1 0 2 2 1 0 0 0 2 2 1 0 1 1 2 1 1 2 1 0 1 1 2 0 2 1 1\n"," 2 2 2 1 2 2 1 1 0 0 2 2 0 1 1 2 0 0 0 2 2 2 0 2 0 0 2 0 2 2 1 1 1 1 1 1 0\n"," 0 0 0 2 1 0 2 0 1 2 1 0 0 1 2 0 1 2 0 2 0 0 1 0 2 0 1 2 0 2 1]\n","2    38\n","0    36\n","1    31\n","Name: 0, dtype: int64\n","모델정확도 0.9555555555555556\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z2JcVjfxAYS8","colab_type":"code","outputId":"3827630d-9457-495f-c0db-7ddc2c1242ce","executionInfo":{"status":"ok","timestamp":1561612444686,"user_tz":-540,"elapsed":725,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# 데이터를 학습용/평가용 데이터로 분할 3 ------------------------------------------------------------------------------------------\n","# 독립변수 속성들 분포를 고려한 표본추출이 필요함\n","\n","# sklearn의 train_test_split을 이용\n","# train_test_spli(독립변수, 종속변수, 훈련데이터크기, 평가데이터크기, 계층추출, 난수초기값)\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n","                                                    train_size=0.7, test_size=0.3,\n","                                                    stratify=iris.target, #-_-??? stratified를 종속변수에?\n","                                                    random_state=1906271240)\n","\n","#print(pd.DataFrame(X_test)[0].value_counts())\n","\n","dt_clf = DecisionTreeClassifier()\n","dt_clf.fit(X_train, y_train)\n","\n","predict = dt_clf.predict(X_test)\n","print('모델정확도', accuracy_score(y_test, predict))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["모델정확도 0.9333333333333333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ns0jhtYGWuDH","colab_type":"code","outputId":"5d9affb5-bf42-42f8-9518-d48c3d68e034","executionInfo":{"status":"ok","timestamp":1561616571170,"user_tz":-540,"elapsed":803,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":908}},"source":["# 교차검증 cross validation\n","# 데이터 수가 적은 경우 데이터 일부인 평가 데이터도 작음\n","# => 성능 평가의 신뢰도 의심\n","\n","# 데이터를 동일한 크기로 k개 나누고, \n","# 이들 중 훈련/평가 데이터를 구분지어 순환적으로 훈련 및 평가를 k번 실시함\n","# => K Fold 교차검증이라 함\n","\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","\n","#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n","#                                                    train_size=0.7, test_size=0.3,\n","#                                                    stratify=iris.target, #-_-??? stratified를 종속변수에?\n","#                                                    random_state=1906271240)\n","\n","kfold = KFold(n_splits=5)\n","accuracies = []\n","n_iter=0 # 검증 회차\n","\n","#print(kfold)\n","\n","#print(pd.DataFrame(X_test)[0].value_counts())\n","\n","dt_clf = DecisionTreeClassifier(random_state=1906271505)\n","\n","#print(iris.data.shape)\n","\n","for tridx, tsidx in kfold.split(iris.data):\n","  #print(tridx)\n","  #print(tsidx)\n","  #print('-------------------')\n","  X_train = iris.data[tridx] \n","  X_test = iris.data[tsidx]\n","  y_train = iris.target[tridx]\n","  y_test = iris.target[tsidx]\n","  \n","  print(pd.DataFrame(y_train)[0].value_counts())\n","  print(pd.DataFrame(y_test)[0].value_counts())\n","  #print('검증세트 인덱스', tridx)\n","  #print('검증세트 인덱스', tsidx)\n","  #print('---------------------------------------------------------------------------')\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  \n","  n_iter +=1\n","  \n","  acc = accuracy_score(y_test, pred)\n","  accuracies.append(acc)\n","  print('----------------------') \n","  print('{0}회차 검증 정확도 {1}'.format(n_iter, acc))\n","  print('---------------------------------------------------------------------------') \n","\n","print('---------------------------------------------------------------------------') \n","print('평균 정확도', np.mean(accuracies))\n"],"execution_count":113,"outputs":[{"output_type":"stream","text":["2    50\n","1    50\n","0    20\n","Name: 0, dtype: int64\n","0    30\n","Name: 0, dtype: int64\n","----------------------\n","1회차 검증 정확도 1.0\n","---------------------------------------------------------------------------\n","2    50\n","1    40\n","0    30\n","Name: 0, dtype: int64\n","0    20\n","1    10\n","Name: 0, dtype: int64\n","----------------------\n","2회차 검증 정확도 0.9666666666666667\n","---------------------------------------------------------------------------\n","2    50\n","0    50\n","1    20\n","Name: 0, dtype: int64\n","1    30\n","Name: 0, dtype: int64\n","----------------------\n","3회차 검증 정확도 0.9\n","---------------------------------------------------------------------------\n","0    50\n","1    40\n","2    30\n","Name: 0, dtype: int64\n","2    20\n","1    10\n","Name: 0, dtype: int64\n","----------------------\n","4회차 검증 정확도 0.9333333333333333\n","---------------------------------------------------------------------------\n","1    50\n","0    50\n","2    20\n","Name: 0, dtype: int64\n","2    30\n","Name: 0, dtype: int64\n","----------------------\n","5회차 검증 정확도 0.7666666666666667\n","---------------------------------------------------------------------------\n","---------------------------------------------------------------------------\n","평균 정확도 0.9133333333333333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yqWRAzgOkLJo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6869028c-8fb9-4dae-eccc-d963623429a4","executionInfo":{"status":"ok","timestamp":1561617542506,"user_tz":-540,"elapsed":835,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["# Strateified K 교차검증\n","# 기존의 교차검증은 종속변수의 범주 비율을 고려하지 않고 훈련 및 평가를 실시했음\n","# 종속변수의 범주 비율을 고려해서 훈련 및 평가를 실시하려면 Stratified K 교차검증을 사용함\n","# 원본 데이터의 범주 분포 특성을 반영해서 훈련/평가를 실시해야 함\n","\n","from sklearn.model_selection import StratifiedKFold\n","#from sklearn.model_selection import cross_val_score\n","\n","#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n","#                                                    train_size=0.7, test_size=0.3,\n","#                                                    stratify=iris.target, #-_-??? stratified를 종속변수에?\n","#                                                    random_state=1906271240)\n","\n","skfold = StratifiedKFold(n_splits=5)\n","accuracies = []\n","n_iter=0 # 검증 회차\n","\n","\n","\n","dt_clf = DecisionTreeClassifier(random_state=1906271525)\n","\n","for tridx, tsidx in skfold.split(iris.data, iris.target): # stratified는 argument가 2개 필요함\n","  #print(tridx)\n","  #print(tsidx)\n","  #print('-------------------')\n","  X_train = iris.data[tridx] \n","  X_test = iris.data[tsidx]\n","  y_train = iris.target[tridx]\n","  y_test = iris.target[tsidx]\n","  \n","  print(pd.DataFrame(y_train)[0].value_counts())\n","  print(pd.DataFrame(y_test)[0].value_counts())\n","  #print('검증세트 인덱스', tridx)\n","  #print('검증세트 인덱스', tsidx)\n","  #print('---------------------------------------------------------------------------')\n","  dt_clf.fit(X_train, y_train)\n","  pred = dt_clf.predict(X_test)\n","  \n","  n_iter +=1\n","  \n","  acc = accuracy_score(y_test, pred)\n","  accuracies.append(acc)\n","  print('----------------------') \n","  print('{0}회차 검증 정확도 {1}'.format(n_iter, acc))\n","  print('---------------------------------------------------------------------------') \n","\n","print('---------------------------------------------------------------------------') \n","print('평균 정확도', np.mean(accuracies))\n"],"execution_count":119,"outputs":[{"output_type":"stream","text":["2    40\n","1    40\n","0    40\n","Name: 0, dtype: int64\n","2    10\n","1    10\n","0    10\n","Name: 0, dtype: int64\n","----------------------\n","1회차 검증 정확도 0.9666666666666667\n","---------------------------------------------------------------------------\n","2    40\n","1    40\n","0    40\n","Name: 0, dtype: int64\n","2    10\n","1    10\n","0    10\n","Name: 0, dtype: int64\n","----------------------\n","2회차 검증 정확도 0.9666666666666667\n","---------------------------------------------------------------------------\n","2    40\n","1    40\n","0    40\n","Name: 0, dtype: int64\n","2    10\n","1    10\n","0    10\n","Name: 0, dtype: int64\n","----------------------\n","3회차 검증 정확도 0.9\n","---------------------------------------------------------------------------\n","2    40\n","1    40\n","0    40\n","Name: 0, dtype: int64\n","2    10\n","1    10\n","0    10\n","Name: 0, dtype: int64\n","----------------------\n","4회차 검증 정확도 0.9666666666666667\n","---------------------------------------------------------------------------\n","2    40\n","1    40\n","0    40\n","Name: 0, dtype: int64\n","2    10\n","1    10\n","0    10\n","Name: 0, dtype: int64\n","----------------------\n","5회차 검증 정확도 1.0\n","---------------------------------------------------------------------------\n","---------------------------------------------------------------------------\n","평균 정확도 0.9600000000000002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7orPqrUEqKmd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f667977e-051d-4647-ae47-cbe060047601","executionInfo":{"status":"ok","timestamp":1561619073679,"user_tz":-540,"elapsed":686,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["# 교차검증을 보다 편하게 하려면?\n","# scikit-learn의 cross_val_score 함수 이용\n","# cross_val_score(분류기, 데이터, 레이블, 평가방식, 폴드수)\n","\n","from sklearn.model_selection import cross_val_score\n","\n","dt_clf = DecisionTreeClassifier(random_state=1906271540)\n","\n","scores = cross_val_score(dt_clf,\n","                        iris.data, iris.target,\n","                        scoring='accuracy', cv=5) # train vs. test 비율 명시할 필요 없고, for문 안 써도 된다는 점에서 편리\n","\n","print('교차검증 정확도', scores)\n","print('평균 교차검증 정확도', np.mean(scores))"],"execution_count":124,"outputs":[{"output_type":"stream","text":["교차검증 정확도 [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n","평균 교차검증 정확도 0.9600000000000002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVp1kKqGwAdX","colab_type":"code","colab":{}},"source":["# GridSearchCV\n","# 교차검증과 최적 하이퍼매개변수 튜닝\n","# 분류나 회귀 등의 알고리즘에 사용되는 하이퍼 매개변수를 순차적으로 입력하면서,\n","# 최적의 매개변수를 찾아주는 방안을 제공\n","# 단, 미리 매개변수 집합을 구성해둬야 함"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"haM2326sxSJf","colab_type":"code","colab":{}},"source":["# 데이터 전처리\n","# 머신러닝 알고리즘을 익히는 것 못지 않게 데이터 전처리 역시 중요한 과정 중 하나.\n","# 무엇보다 머신러닝 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 하는 기본사항이 존재.\n","\n","# 결측치 처리 : NaN, Null은 허용되지 않음\n","# 원핫인코딩 : 머신러닝 알고리즘들은 문자열 값을 데이터의 입력값으로 허용하지 않음. 따라서, 모든 문자열 값은 인코딩해서 숫자형으로 변환해둬야 함.\n","# 한편, 텍스트 데이터들은 벡터화해서 처리\n","\n","# 머신러닝을 위한 인코딩은 \"레이블인코딩\"과 \"원핫인코딩\"이 있음"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxUo4lon09R9","colab_type":"code","colab":{}},"source":["import sklearn\n","import image\n","import seaborn as sns\n","from sklearn.datasets import load_iris\n","from sklearn.datasets import load_boston\n","from sklearn.datasets import load_digits\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.datasets import make_blobs\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","import pandas as pd\n","from pandas.plotting import scatter_matrix\n","import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Epkpg4qE09xP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"b50118cc-3ca6-46c4-98e3-54c3dc0efc19","executionInfo":{"status":"ok","timestamp":1561621161688,"user_tz":-540,"elapsed":730,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["# 레이블인코딩 label encoding ----------------------------------------\n","# 범주형 값을 숫자값으로 변환하는 것을 의미\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","items = ['TV','Fridge','Stove','Airconditioner','Computer']\n","\n","encoder = LabelEncoder()\n","encoder.fit(items) # 먼저 fit 시킴. 적절하게 정렬..? 그것만인가.\n","labels = encoder.transform(items)\n","\n","print(labels)\n","print(encoder.classes_) # 순서 > 오름차순 정렬\n","\n","\n","print(encoder.inverse_transform([0,3])) # 인코딩 된 값을 다시 디코딩해서 출력. bracket 안의 값은 배열리스트 내 위치값\n","print(encoder.inverse_transform([1,3,4])) # 인코딩 된 값을 다시 디코딩해서 출력. bracket 안의 값은 배열리스트 내 위치값\n","\n","# 문자열 값을 숫자형 값으로 변환시켰을 때 발생할 수 있는 문제는 각 값의 대소관계를 통해 중요도 여부가 존재할 수 있음\n","# 즉, 인코딩 된 값에 서수ordinal 척도가 생길 수 있음\n","\n","# 따라서 대소관계가 있는 데이터로 분석을 할 경우 정확도에 영향을 미칠 수 있음\n","# => 원핫인코딩을 사용함으로써 문제 해결"],"execution_count":148,"outputs":[{"output_type":"stream","text":["[4 2 3 0 1]\n","['Airconditioner' 'Computer' 'Fridge' 'Stove' 'TV']\n","['Airconditioner' 'Stove']\n","['Computer' 'Stove' 'TV']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X8D0qzdr3-OE","colab_type":"code","colab":{}},"source":["# 원핫인코딩\n","# 범주 값의 유형에 따라 더미변수dummy variable를 추가해 고유값을\n","# 해당하는 컬럼에만 1을 표시하고 나머지는 0으로 표시하는 방식\n","\n","# '티비'  '냉장고'  '가스렌지'  '에어콘'  '컴퓨터'\n","# 1         0          0           0        0\n","# 0         1          0           0        0\n","# 0         0          1           0        0\n","# 0         0          0           1        0\n","# 0         0          0           0        1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvhUV-D45Kru","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":492},"outputId":"ff612ec5-e64c-4b6a-c980-e8ef22c3c410","executionInfo":{"status":"ok","timestamp":1561623114830,"user_tz":-540,"elapsed":525,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","items = ['TV','Fridge','Stove','Airconditioner','Computer']\n","\n","# 먼저, labelEncoder로 문자열을 숫자값으로 변환\n","\n","encoder = LabelEncoder()\n","encoder.fit(items)\n","labels = encoder.transform(items)\n","\n","print(labels)\n","print('--------------------------------------')\n","#print(encoder.classes_) # 순서 > 오름차순 정렬\n","\n","\n","#print(encoder.inverse_transform([0,3])) # 인코딩 된 값을 다시 디코딩해서 출력. bracket 안의 값은 배열리스트 내 위치값\n","#print(encoder.inverse_transform([1,3,4])) # 인코딩 된 값을 다시 디코딩해서 출력. bracket 안의 값은 배열리스트 내 위치값\n","\n","\n","# 1차원 데이터를 2차원 데이터로 변환\n","\n","labels = labels.reshape(-1, 1) # -1 : 행을 열로 전환\n","#labels = labels.reshape(5, 1)\n","print(labels)\n","print('--------------------------------------')\n","\n","# 원핫인코딩 적용\n","onehot = OneHotEncoder()\n","onehot.fit(labels)\n","onehotlabels = onehot.transform(labels)\n","print(onehotlabels.shape)\n","print('--------------------------------------')\n","print(onehotlabels)\n","print('--------------------------------------')\n","# 위 프린트 찍은 것으로는 와닿지 않음\n","\n","print(onehotlabels.toarray())\n","\n","# 위에서 보듯 sklearn의 원핫인코딩 API는 사용불편. 원핫인코딩 변환 전 레이블 인코딩이 선행되어야 하기에."],"execution_count":169,"outputs":[{"output_type":"stream","text":["[4 2 3 0 1]\n","--------------------------------------\n","[[4]\n"," [2]\n"," [3]\n"," [0]\n"," [1]]\n","--------------------------------------\n","(5, 5)\n","--------------------------------------\n","  (0, 4)\t1.0\n","  (1, 2)\t1.0\n","  (2, 3)\t1.0\n","  (3, 0)\t1.0\n","  (4, 1)\t1.0\n","--------------------------------------\n","[[0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0.]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ExeYavoM_bG9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":198},"outputId":"c992a44b-3f2a-4198-d56a-7d8b5d8564ab","executionInfo":{"status":"ok","timestamp":1561623227857,"user_tz":-540,"elapsed":731,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["# pandas의 원핫인코딩 API가 훨씬 편함\n","# get_dummies() 함수 이용\n","# 단, 변환대상은 데이터프레임으로 작성되어있어야 함!!\n","\n","items = ['TV','Fridge','Stove','Airconditioner','Computer']\n","df = pd.DataFrame(items)\n","pd.get_dummies(df) # 이렇게 하면 컬럼명에 0_ 이 붙어서 나옴 "],"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0_Airconditioner</th>\n","      <th>0_Computer</th>\n","      <th>0_Fridge</th>\n","      <th>0_Stove</th>\n","      <th>0_TV</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0_Airconditioner  0_Computer  0_Fridge  0_Stove  0_TV\n","0                 0           0         0        0     1\n","1                 0           0         1        0     0\n","2                 0           0         0        1     0\n","3                 1           0         0        0     0\n","4                 0           1         0        0     0"]},"metadata":{"tags":[]},"execution_count":172}]},{"cell_type":"code","metadata":{"id":"PMpYgiGg_2qa","colab_type":"code","colab":{}},"source":["# 특성feature 스케일링과 표준화/정규화\n","\n","# 서로 다른 범위, 단위의 변수 값을 일정수준으로 맞추는 작업을 특성 스케일링이라 함\n","# 이것을 구현하는 방법은 정규화와 표준화가 있음\n","\n","# 어떤 데이터의 값이 정수와 실수가 혼용되어 있다든지\n","# 값의 범위가 1~100, 0~0.001, 1~10000 등등의 경우\n","# 데이터 분석 시 제대로 된 결과가 나오지 않을 수 있음\n","# => 많은 cpu 파워와 메모리가 필요하고 학습이 느려질 수 있음\n","\n","\n","# 이것을 구현하는 방법은 정규화와 표준화가 있음\n","\n","# StandardScaler : 평균 0, 표준편차 1로 변환 ----------------------------------------------------------- Scaler1\n","# MinMaxScaler : 최소값 0, 최대값 0 되도록 변환 ----------------------------------------------------------- Scaler2\n","\n","# 이상치outlier 있는 경우\n","# MinMaxScaler는 outlier 영향을 꽤나 받음. StandardScaler는 상대적으로 덜 받지만, 이왕이면 outlier는 제거하는게 나음\n","\n","# RobustScaler : 중앙값 0, IQR 1 되도록 변환?? 뭔말 <- 정규분포를 띄되, 분포가 넓게 배치되도록 조정! ----------------------------------------------------------- Scaler3\n","# => IQR : 3사분위수와 1사분위수를 다룸\n","# 즉, 데이터의 상위 25%와 하위 75% 값을 다룸"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGcFfm4YB091","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6ca868aa-9d58-4cfe-bfba-e20ce7c032aa","executionInfo":{"status":"ok","timestamp":1561624420456,"user_tz":-540,"elapsed":680,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["X = np.arange(9, dtype=np.float) - 3\n","#X = np.arange(9, dtype=np.float)\n","X = X.reshape(-1, 1)\n","\n","print(pd.DataFrame(X))\n","print(pd.DataFrame(X).describe())\n","print('--------------------------------------')\n","\n","X = np.vstack([X, 100]) # 이상치 추가 (아랫쪽에) <- MinMaxScaler는 outlier 영향을 꽤나 받음. StandardScaler는 상대적으로 덜 받지만, 이왕이면 outlier는 제거하는게 나음\n","print(pd.DataFrame(X))\n","print(pd.DataFrame(X).describe())\n","print('--------------------------------------')\n","\n","# StandardScaler 적용------------------------------------------------------\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X)\n","xx = scaler.transform(X)\n","print(xx)\n","print('--------------------------------------')\n","print(pd.DataFrame(xx).describe())\n","print('--------------------------------------')\n","print(np.mean(xx), np.std(xx))"],"execution_count":187,"outputs":[{"output_type":"stream","text":["     0\n","0 -3.0\n","1 -2.0\n","2 -1.0\n","3  0.0\n","4  1.0\n","5  2.0\n","6  3.0\n","7  4.0\n","8  5.0\n","              0\n","count  9.000000\n","mean   1.000000\n","std    2.738613\n","min   -3.000000\n","25%   -1.000000\n","50%    1.000000\n","75%    3.000000\n","max    5.000000\n","--------------------------------------\n","       0\n","0   -3.0\n","1   -2.0\n","2   -1.0\n","3    0.0\n","4    1.0\n","5    2.0\n","6    3.0\n","7    4.0\n","8    5.0\n","9  100.0\n","                0\n","count   10.000000\n","mean    10.900000\n","std     31.412842\n","min     -3.000000\n","25%     -0.750000\n","50%      1.500000\n","75%      3.750000\n","max    100.000000\n","--------------------------------------\n","[[-0.46642982]\n"," [-0.43287372]\n"," [-0.39931762]\n"," [-0.36576152]\n"," [-0.33220541]\n"," [-0.29864931]\n"," [-0.26509321]\n"," [-0.23153711]\n"," [-0.197981  ]\n"," [ 2.98984872]]\n","--------------------------------------\n","                  0\n","count  1.000000e+01\n","mean  -4.440892e-17\n","std    1.054093e+00\n","min   -4.664298e-01\n","25%   -3.909286e-01\n","50%   -3.154274e-01\n","75%   -2.399261e-01\n","max    2.989849e+00\n","--------------------------------------\n","0.0 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TxRU3iChEZ05","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":417},"outputId":"4fc3d0ed-356f-4301-f01f-ea872f852796","executionInfo":{"status":"ok","timestamp":1561625021468,"user_tz":-540,"elapsed":755,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["X = np.arange(9, dtype=np.float) - 3\n","#X = np.arange(9, dtype=np.float)\n","X = X.reshape(-1, 1)\n","\n","#print(pd.DataFrame(X))\n","#print(pd.DataFrame(X).describe())\n","#print('--------------------------------------')\n","\n","X = np.vstack([X, 100]) # 이상치 추가 (아랫쪽에) <- MinMaxScaler는 outlier 영향을 꽤나 받음. StandardScaler는 상대적으로 덜 받지만, 이왕이면 outlier는 제거하는게 나음\n","#print(pd.DataFrame(X))\n","#print(pd.DataFrame(X).describe())\n","#print('--------------------------------------')\n","\n","# MinMaxScaler 적용------------------------------------------------------\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaler.fit(X)\n","xx = scaler.transform(X)\n","print(xx)\n","print('--------------------------------------')\n","print(pd.DataFrame(xx).describe())\n","print('--------------------------------------')\n","print(np.min(xx), np.max(xx))"],"execution_count":192,"outputs":[{"output_type":"stream","text":["[[0.        ]\n"," [0.00970874]\n"," [0.01941748]\n"," [0.02912621]\n"," [0.03883495]\n"," [0.04854369]\n"," [0.05825243]\n"," [0.06796117]\n"," [0.0776699 ]\n"," [1.        ]]\n","--------------------------------------\n","               0\n","count  10.000000\n","mean    0.134951\n","std     0.304979\n","min     0.000000\n","25%     0.021845\n","50%     0.043689\n","75%     0.065534\n","max     1.000000\n","--------------------------------------\n","0.0 0.9999999999999999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dwl-Yx13Gsik","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":454},"outputId":"dc9c6a1b-8ce3-4ff2-f7ac-52c84ffb53ee","executionInfo":{"status":"ok","timestamp":1561625124706,"user_tz":-540,"elapsed":806,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}}},"source":["from sklearn.preprocessing import RobustScaler \n","\n","\n","X = np.arange(9, dtype=np.float) - 3\n","#X = np.arange(9, dtype=np.float)\n","X = X.reshape(-1, 1)\n","\n","#print(pd.DataFrame(X))\n","#print(pd.DataFrame(X).describe())\n","#print('--------------------------------------')\n","\n","X = np.vstack([X, 100]) # 이상치 추가 (아랫쪽에) <- MinMaxScaler는 outlier 영향을 꽤나 받음. StandardScaler는 상대적으로 덜 받지만, 이왕이면 outlier는 제거하는게 나음\n","#print(pd.DataFrame(X))\n","#print(pd.DataFrame(X).describe())\n","#print('--------------------------------------')\n","\n","# RobustScaler 적용------------------------------------------------------\n","\n","scaler = RobustScaler()\n","scaler.fit(X)\n","zz = scaler.transform(X)\n","print(zz)\n","print('--------------------------------------')\n","print(pd.DataFrame(zz).describe())\n","print('--------------------------------------')\n","print(np.mean(zz))\n","print(np.median(zz))\n","print(np.std(zz))"],"execution_count":196,"outputs":[{"output_type":"stream","text":["[[-1.        ]\n"," [-0.77777778]\n"," [-0.55555556]\n"," [-0.33333333]\n"," [-0.11111111]\n"," [ 0.11111111]\n"," [ 0.33333333]\n"," [ 0.55555556]\n"," [ 0.77777778]\n"," [21.88888889]]\n","--------------------------------------\n","               0\n","count  10.000000\n","mean    2.088889\n","std     6.980632\n","min    -1.000000\n","25%    -0.500000\n","50%     0.000000\n","75%     0.500000\n","max    21.888889\n","--------------------------------------\n","2.088888888888889\n","0.0\n","6.622408647636923\n"],"name":"stdout"}]}]}